model_list:
  - model_name: gpt-4o-mini ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: bedrock/mistral.mistral-small-2402-v1:0 ### MODEL NAME sent to `litellm.completion()` ###

  - model_name: gpt-4o ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: bedrock/mistral.mistral-large-2402-v1:0 ### MODEL NAME sent to `litellm.completion()` ###

  - model_name: lite-text ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: bedrock/mistral.mixtral-8x7b-instruct-v0:1 ### MODEL NAME sent to `litellm.completion()` ###
  
  - model_name: claude-3-5-sonnet ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0 ### MODEL NAME sent to `litellm.completion()` ###


  - model_name: "*" 
    litellm_params:
      model: "*"

litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  drop_params: True
  success_callback: ["langfuse"] # OPTIONAL - if you want to start sending LLM Logs to Langfuse. Make sure to set `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` in your env

general_settings: 
  master_key: sk-gyt # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)
  # alerting: ["slack"] # [OPTIONAL] If you want Slack Alerts for Hanging LLM requests, Slow llm responses, Budget Alerts. Make sure to set `SLACK_WEBHOOK_URL` in your env
  database_url: os.environ/DATABASE_URL
  store_prompts_in_spend_logs: True